Certification prep:
    Apache Kafka Fundamentals and Accreditation
        Mod 1: Student Handbook
                Exercise Book
        Mod 2: Lab Access  
            Confluent Training Platform Guide
            Lab Virtual Machine FUN 
        Mod 4: Video Lectures
            Mod 1 - Mod 7


Kafka notes

Why?
Shift from static snapshot to continuous
Single platform connects everyone to every event
Real time stream of events
All events stores for historical view

Lab 01 - Exploring Apache Kafka in the Exercise Book.

Fundamentals
Key elements of Kafka and their responsibilities
    Producer sends data to Kafka
        Optional; Kafka sends ack or nack back (acknowledged, not ack)
        Many producers send data to Kafka concurrently
    Brokers: Kafka consists of a bunch of Brokers / cluster of Brokers
        Broker receives data from Producers and store temporarily in page cache or permanently on disk after the OS flushes page cache
        Brokers keep the data ready for downstream consumers
        Data is kept per retention time (1 week default)
    Consumers: Poll the data from Kafka
        Many consumers can poll Kafka for data
        Conumers are organized in consumer groups which split the work to allow parallelism
    Zookeeper: Cluster of instances that form an ensemble
        Kafka Cluster management
        Failure detection and recovery
        Store Access Control Lists (ACLs) for Kafka cluster authorization
        Distributed Key Value Store
        3-5 servers form an ensemble
Producers are decoupled from Consumers
    Slow consumers do not affect producers
    Consumer failure does not affect System
    They need to agree on data format
Topic, Partitions, Segments
    Topics: Streams of related messages in Kafka
        Producer : Topic: N to N relations
        Unlimited number of Topics
        Topic: Like a group of data (Broken glass, person fell)
    Partition: Kafka splits a single topic into many partitions 
        The partition is handled by a single Kafka Broker
        Partition can be viewed as a log
    Segment:
        Broker stores the messages as they come in memory / page cache, then flushes them to a physical file 
        Portion of a Partition
    Log: Data structure like a queue of elements
        New elements are appended to the end of the log
    Log structured data flow:
        Data -> Log -> Destination
        Destination consumes in temporal order
    The Stream:
        Sequence of events
        Began sometime in the past 
        Stream is open-ended; we don't know when the stream will stop 
        We therefore don't know how much data to expect in the future
        Stream is immutable; we don't modify the existing stream but instead generate a new output 
    Data Elements:
        Data element in a log (or topic) is called a record
        Record is also message or event
        Consists of metadata and a body
            Metadata contains offset, compression, magic byte, timestamp, optional headers 
            Body consists of a Key and Value 
                Value is usually business-relevant data 
                Key is used to decied into which partition record is written
                Important because ordering is only guaranteed on a partition, not on a topic level!
    Brokers Manage Partitions: page 53   
        Messages of Topic spread across Partitions
        Partitions spread across Brokers
        Each Broker handles many Partitions  
        Each Partition stored on Broker's disk
        Partition 1 . . n log files
        Each message in Log id'd by offset
        Configureable Retention Policy
    Broker Basics
        Producer sends Messages to Brokers
        Brokers receive and store Messages
        Kafka Cluster can have many Brokers
        Each Broker manages multiple Partitions
    Broker Replication
        Kafka can replicate partitions for fault tolerance
        Each partition has a leader server and 0 or more follower servers
        Leaders handle the read/write requests for a partition
        E.g. 4 brokers and 3 replicated partitions = replication factor 3 = 1 leader + 2 followers
    Producer Basics
        Producer writes Data as Messages to the Kafka cluster
        Any language
        Command Line Producer Tool
    Load Balancing and Semantics





